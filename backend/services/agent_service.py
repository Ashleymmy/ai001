"""Agent æœåŠ¡ - æ™ºèƒ½è§†é¢‘åˆ¶ä½œåŠ©æ‰‹

åŸºäº Flova Agent æ¶æ„è®¾è®¡ï¼Œå®ç°ï¼š
1. å¯¹è¯å¼ AI åŠ©æ‰‹ - ç†è§£ç”¨æˆ·éœ€æ±‚ï¼Œåˆ¶å®šåˆ¶ä½œæ–¹æ¡ˆ
2. å…ƒç´ å¼•ç”¨ç³»ç»Ÿ - [Element_XXX] æœºåˆ¶ç¡®ä¿è§’è‰²ä¸€è‡´æ€§
3. åˆ†é•œè§„åˆ’ç³»ç»Ÿ - Segment â†’ Shot ç»“æ„
4. æç¤ºè¯æ¨¡æ¿ç³»ç»Ÿ - ç»“æ„åŒ–æç¤ºè¯ç”Ÿæˆ
5. æ‰¹é‡ç”Ÿæˆæµç¨‹ - è‡ªåŠ¨åŒ–è§†é¢‘åˆ¶ä½œ
"""
import os
import json
import uuid
import re
import asyncio
from datetime import datetime
from typing import Optional, List, Dict, Any, Callable
from openai import AsyncOpenAI
from .storage_service import StorageService

# é•œå¤´ç±»å‹å®šä¹‰
SHOT_TYPES = {
    "standard": {"name": "æ ‡å‡†å™äº‹é•œå¤´", "duration": "5-6ç§’", "description": "ç”¨äºå¸¸è§„å™äº‹"},
    "quick": {"name": "å¿«é€Ÿåˆ‡æ¢", "duration": "3-4ç§’", "description": "ç”¨äºå…³é”®è½¬æŠ˜ç‚¹"},
    "closeup": {"name": "ç‰¹å†™é•œå¤´", "duration": "4-5ç§’", "description": "å¼ºè°ƒç»†èŠ‚å’Œæƒ…ç»ª"},
    "wide": {"name": "è¿œæ™¯é•œå¤´", "duration": "6-8ç§’", "description": "å±•ç¤ºç¯å¢ƒå’Œåœºæ™¯"},
    "montage": {"name": "è’™å¤ªå¥‡", "duration": "8-12ç§’", "description": "å¤šç”»é¢å¿«é€Ÿåˆ‡æ¢"}
}

# Agent ç³»ç»Ÿæç¤ºè¯ - YuanYuan é£æ ¼
AGENT_SYSTEM_PROMPT = """ä½ æ˜¯ YuanYuanï¼Œä¸€ä½ä¸“ä¸šä¸”å‹å¥½çš„ AI è§†é¢‘åˆ¶ä½œåŠ©æ‰‹ã€‚ä½ çš„å¯¹è¯é£æ ¼æ¸©æš–ã€ä¸“ä¸šï¼Œå–„äºç”¨åˆ†æ­¥éª¤çš„æ–¹å¼è§£é‡Šå¤æ‚çš„åˆ¶ä½œæµç¨‹ã€‚

## ä½ çš„äººè®¾
- åå­—ï¼šYuanYuan
- æ€§æ ¼ï¼šä¸“ä¸šã€è€å¿ƒã€å‹å¥½ã€ä¹äºåŠ©äºº
- è¯´è¯é£æ ¼ï¼šæ¸…æ™°ã€æœ‰æ¡ç†ï¼Œå–œæ¬¢ç”¨ã€Œç¬¬ä¸€æ­¥ã€ã€Œç¬¬äºŒæ­¥ã€ã€Œç¬¬ä¸‰æ­¥ã€æ¥è§£é‡Šæµç¨‹
- ç‰¹ç‚¹ï¼šä¼šåœ¨å…³é”®èŠ‚ç‚¹ç­‰å¾…ç”¨æˆ·ç¡®è®¤ï¼Œä¸ä¼šä¸€æ¬¡æ€§åšå¤ªå¤šäº‹æƒ…

## ä½ çš„èƒ½åŠ›
1. **éœ€æ±‚ç†è§£**: åˆ†æç”¨æˆ·çš„æ•…äº‹æè¿°ï¼Œæå–å…³é”®ä¿¡æ¯
2. **é¡¹ç›®è§„åˆ’**: åˆ¶å®šå®Œæ•´çš„åˆ¶ä½œæ–¹æ¡ˆï¼ŒåŒ…æ‹¬åˆ›æ„ç®€æŠ¥ã€å‰§æœ¬ã€åˆ†é•œè®¾è®¡
3. **è§’è‰²è®¾è®¡**: ä¸ºæ•…äº‹ä¸­çš„è§’è‰²ç”Ÿæˆè¯¦ç»†çš„è§†è§‰æè¿°
4. **åˆ†é•œæ‹†è§£**: å°†å‰§æœ¬è½¬åŒ–ä¸ºå…·ä½“çš„é•œå¤´åºåˆ—
5. **æç¤ºè¯ä¼˜åŒ–**: ç”Ÿæˆé€‚åˆ AI å›¾åƒ/è§†é¢‘ç”Ÿæˆçš„æç¤ºè¯

## å¯¹è¯é£æ ¼ç¤ºä¾‹
- å¼€å§‹ä»»åŠ¡æ—¶ï¼šã€Œæ”¶åˆ°ï¼è®©æˆ‘æ¥åˆ†æä½ çš„éœ€æ±‚... ğŸ¤”ã€
- è§£é‡Šæµç¨‹æ—¶ï¼šã€Œ**ç¬¬ä¸€æ­¥** æˆ‘ä¼šå…ˆåˆ›å»ºé¡¹ç›®æ¦‚è¦\n**ç¬¬äºŒæ­¥** ç¼–å†™å‰§æœ¬å¹¶è®¾è®¡åˆ†é•œ\n**ç¬¬ä¸‰æ­¥** ç”Ÿæˆè§’è‰²è®¾è®¡å›¾ã€
- å®Œæˆé˜¶æ®µæ—¶ï¼šã€Œâœ… Agentåˆ†æå®Œæˆï¼ã€
- ç­‰å¾…ç¡®è®¤æ—¶ï¼šã€Œæ¥ä¸‹æ¥ï¼Œä½ å¯ä»¥é€‰æ‹©ï¼š\n1. å…ˆè®©æˆ‘çœ‹çœ‹åˆ†é•œ\n2. ä¸€é”®ç”Ÿæˆå…¨éƒ¨\n3. å…ˆç”Ÿæˆè§’è‰²å›¾ç‰‡ã€

## å·¥ä½œæµç¨‹
1. æ¥æ”¶ç”¨æˆ·éœ€æ±‚åï¼Œå…ˆåˆ†æå¹¶ç¡®è®¤ç†è§£
2. ç”Ÿæˆé¡¹ç›®è§„åˆ’æ–‡æ¡£ï¼ˆCreative Briefï¼‰
3. ç¼–å†™å‰§æœ¬å¹¶æ‹†è§£ä¸ºåˆ†é•œ
4. è®¾è®¡å…³é”®è§’è‰²å’Œå…ƒç´ 
5. ä¸ºæ¯ä¸ªé•œå¤´ç”Ÿæˆè¯¦ç»†çš„æç¤ºè¯
6. åœ¨å…³é”®èŠ‚ç‚¹ç­‰å¾…ç”¨æˆ·ç¡®è®¤

## å…ƒç´ å¼•ç”¨æœºåˆ¶
ä½¿ç”¨ [Element_XXX] æ ¼å¼å¼•ç”¨é¢„ç”Ÿæˆçš„è§’è‰²å’Œç‰©å“ï¼Œç¡®ä¿è§†è§‰ä¸€è‡´æ€§ã€‚
ä¾‹å¦‚ï¼š[Element_YOUNG_SERVANT]ã€[Element_WHITE_SNAKE]

## æç¤ºè¯ç»“æ„
[é•œå¤´ç±»å‹] + [æ—¶é•¿] + [ä¸»ä½“åŠ¨ä½œ] + [åœºæ™¯å…ƒç´ ] + [å…‰çº¿æ°›å›´] + [ç”»é¢è´¨æ„Ÿ] + [æ—ç™½å¯¹é½]

## è¾“å‡ºæ ¼å¼
ä½¿ç”¨ JSON æ ¼å¼è¾“å‡ºç»“æ„åŒ–æ•°æ®ï¼Œä¾¿äºç³»ç»Ÿè§£æå’Œå¤„ç†ã€‚
"""

# é¡¹ç›®è§„åˆ’æç¤ºè¯
PROJECT_PLANNING_PROMPT = """è¯·æ ¹æ®ç”¨æˆ·çš„éœ€æ±‚ï¼Œç”Ÿæˆå®Œæ•´çš„é¡¹ç›®è§„åˆ’ã€‚

ç”¨æˆ·éœ€æ±‚ï¼š{user_request}

è¯·è¾“å‡ºä»¥ä¸‹ JSON æ ¼å¼çš„é¡¹ç›®è§„åˆ’ï¼š
```json
{{
  "creative_brief": {{
    "title": "é¡¹ç›®æ ‡é¢˜",
    "video_type": "è§†é¢‘ç±»å‹ï¼ˆNarrative Story/Commercial/Tutorialç­‰ï¼‰",
    "narrative_driver": "å™äº‹é©±åŠ¨ï¼ˆæ—ç™½é©±åŠ¨/å¯¹è¯é©±åŠ¨/çº¯è§†è§‰ï¼‰",
    "emotional_tone": "æƒ…æ„ŸåŸºè°ƒ",
    "visual_style": "è§†è§‰é£æ ¼",
    "duration": "é¢„è®¡æ—¶é•¿",
    "aspect_ratio": "ç”»é¢æ¯”ä¾‹",
    "language": "è¯­è¨€"
  }},
  "elements": [
    {{
      "id": "Element_XXX",
      "name": "å…ƒç´ åç§°",
      "type": "character/object/scene",
      "description": "è¯¦ç»†çš„è§†è§‰æè¿°ï¼Œç”¨äºå›¾åƒç”Ÿæˆ"
    }}
  ],
  "segments": [
    {{
      "id": "Segment_XXX",
      "name": "æ®µè½åç§°",
      "description": "æ®µè½æè¿°",
      "shots": [
        {{
          "id": "Shot_XXX",
          "name": "é•œå¤´åç§°",
          "type": "standard/quick/closeup/wide/montage",
          "duration": "é¢„è®¡æ—¶é•¿",
          "description": "é•œå¤´æè¿°",
          "prompt": "å®Œæ•´çš„å›¾åƒ/è§†é¢‘ç”Ÿæˆæç¤ºè¯",
          "narration": "å¯¹åº”çš„æ—ç™½æ–‡æœ¬"
        }}
      ]
    }}
  ],
  "cost_estimate": {{
    "elements": "å…ƒç´ ç”Ÿæˆé¢„ä¼°ç§¯åˆ†",
    "shots": "é•œå¤´ç”Ÿæˆé¢„ä¼°ç§¯åˆ†",
    "audio": "éŸ³é¢‘ç”Ÿæˆé¢„ä¼°ç§¯åˆ†",
    "total": "æ€»è®¡é¢„ä¼°ç§¯åˆ†"
  }}
}}
```

æ³¨æ„ï¼š
1. å…ƒç´ æè¿°è¦è¯¦ç»†ï¼Œé€‚åˆ AI å›¾åƒç”Ÿæˆ
2. é•œå¤´æç¤ºè¯è¦åŒ…å«å…ƒç´ å¼•ç”¨ [Element_XXX]
3. æ¯ä¸ªé•œå¤´éƒ½è¦æœ‰å¯¹åº”çš„æ—ç™½
4. åˆç†ä¼°ç®—æˆæœ¬
"""

# å…ƒç´ ç”Ÿæˆæç¤ºè¯æ¨¡æ¿
ELEMENT_PROMPT_TEMPLATE = """è¯·ä¸ºä»¥ä¸‹è§’è‰²/å…ƒç´ ç”Ÿæˆè¯¦ç»†çš„å›¾åƒç”Ÿæˆæç¤ºè¯ï¼š

å…ƒç´ åç§°ï¼š{element_name}
å…ƒç´ ç±»å‹ï¼š{element_type}
åŸºç¡€æè¿°ï¼š{base_description}
è§†è§‰é£æ ¼ï¼š{visual_style}

è¯·è¾“å‡ºé€‚åˆ AI å›¾åƒç”Ÿæˆçš„è‹±æ–‡æç¤ºè¯ï¼ŒåŒ…å«ï¼š
1. ä¸»ä½“æè¿°ï¼ˆå¤–è²Œã€æœè£…ã€å§¿æ€ï¼‰
2. é£æ ¼æè¿°ï¼ˆç”»é£ã€è´¨æ„Ÿï¼‰
3. å…‰çº¿å’Œæ°›å›´
4. ç”»é¢è´¨é‡å…³é”®è¯

è¾“å‡ºæ ¼å¼ï¼š
```json
{{
  "prompt": "è‹±æ–‡æç¤ºè¯",
  "negative_prompt": "è´Ÿé¢æç¤ºè¯",
  "recommended_resolution": "æ¨èåˆ†è¾¨ç‡"
}}
```
"""

# é•œå¤´æç¤ºè¯æ¨¡æ¿
SHOT_PROMPT_TEMPLATE = """è¯·ä¸ºä»¥ä¸‹é•œå¤´ç”Ÿæˆè¯¦ç»†çš„è§†é¢‘ç”Ÿæˆæç¤ºè¯ï¼š

é•œå¤´åç§°ï¼š{shot_name}
é•œå¤´ç±»å‹ï¼š{shot_type}
é•œå¤´æè¿°ï¼š{shot_description}
æ¶‰åŠå…ƒç´ ï¼š{elements}
è§†è§‰é£æ ¼ï¼š{visual_style}
æ—ç™½å†…å®¹ï¼š{narration}

è¯·è¾“å‡ºé€‚åˆ AI è§†é¢‘ç”Ÿæˆçš„æç¤ºè¯ï¼Œæ ¼å¼ï¼š
```json
{{
  "image_prompt": "èµ·å§‹å¸§å›¾åƒæç¤ºè¯ï¼ˆè‹±æ–‡ï¼‰",
  "video_prompt": "è§†é¢‘åŠ¨æ€æç¤ºè¯ï¼ˆè‹±æ–‡ï¼‰",
  "camera_movement": "é•œå¤´è¿åŠ¨æè¿°",
  "duration_seconds": é¢„è®¡ç§’æ•°
}}
```
"""


class AgentService:
    """Agent æœåŠ¡ - æ™ºèƒ½è§†é¢‘åˆ¶ä½œåŠ©æ‰‹"""
    
    def __init__(self, storage: StorageService):
        self.storage = storage
        self.client: Optional[AsyncOpenAI] = None
        self.model = "qwen-plus"
        self._init_client()
    
    def _init_client(self):
        """åˆå§‹åŒ– LLM å®¢æˆ·ç«¯"""
        settings = self.storage.get_settings()
        llm_config = settings.get("llm", {})
        
        api_key = llm_config.get("apiKey") or os.getenv("LLM_API_KEY", "")
        if not api_key:
            print("[Agent] æœªé…ç½® LLM API Key")
            return
        
        provider = llm_config.get("provider", "qwen")
        base_url = llm_config.get("baseUrl", "https://dashscope.aliyuncs.com/compatible-mode/v1")
        self.model = llm_config.get("model", "qwen-plus")
        
        # å¤„ç†è‡ªå®šä¹‰é…ç½®
        if provider.startswith("custom_"):
            custom_providers = self.storage.get_custom_providers()
            custom_config = custom_providers.get(provider, {})
            if custom_config:
                api_key = custom_config.get("apiKey", api_key)
                base_url = custom_config.get("baseUrl", base_url)
                self.model = custom_config.get("model", self.model)
        
        self.client = AsyncOpenAI(api_key=api_key, base_url=base_url)
        print(f"[Agent] åˆå§‹åŒ–å®Œæˆ: model={self.model}")
    
    async def chat(self, message: str, context: Optional[Dict] = None) -> Dict[str, Any]:
        """å¯¹è¯æ¥å£ - å¤„ç†ç”¨æˆ·æ¶ˆæ¯å¹¶è¿”å›ç»“æ„åŒ–å“åº”"""
        if not self.client:
            return {
                "type": "text",
                "content": "è¯·å…ˆåœ¨è®¾ç½®ä¸­é…ç½® LLM API Key ä»¥å¯ç”¨ AI åŠ©æ‰‹åŠŸèƒ½ã€‚"
            }
        
        try:
            # æ„å»ºæ¶ˆæ¯
            messages = [{"role": "system", "content": AGENT_SYSTEM_PROMPT}]
            
            # æ·»åŠ ä¸Šä¸‹æ–‡
            if context:
                context_str = json.dumps(context, ensure_ascii=False, indent=2)
                messages.append({
                    "role": "system",
                    "content": f"å½“å‰é¡¹ç›®ä¸Šä¸‹æ–‡ï¼š\n{context_str}"
                })
            
            messages.append({"role": "user", "content": message})
            
            # è°ƒç”¨ LLM
            response = await self.client.chat.completions.create(
                model=self.model,
                messages=messages,
                temperature=0.7,
                max_tokens=4000
            )
            
            reply = response.choices[0].message.content or ""
            
            # å°è¯•è§£æ JSON å“åº”
            parsed = self._parse_response(reply)
            return parsed
            
        except Exception as e:
            print(f"[Agent] å¯¹è¯å¤±è´¥: {e}")
            return {
                "type": "error",
                "content": f"AI åŠ©æ‰‹è°ƒç”¨å¤±è´¥: {str(e)}"
            }
    
    async def plan_project(self, user_request: str, style: str = "å‰åœåŠ›2D") -> Dict[str, Any]:
        """è§„åˆ’é¡¹ç›® - æ ¹æ®ç”¨æˆ·éœ€æ±‚ç”Ÿæˆå®Œæ•´çš„é¡¹ç›®è§„åˆ’"""
        if not self.client:
            return {"error": "æœªé…ç½® LLM API Key"}
        
        try:
            prompt = PROJECT_PLANNING_PROMPT.format(user_request=user_request)
            
            response = await self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": AGENT_SYSTEM_PROMPT},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.8,
                max_tokens=6000
            )
            
            reply = response.choices[0].message.content or ""
            
            # æå– JSON
            json_match = re.search(r'```json\s*([\s\S]*?)\s*```', reply)
            if json_match:
                plan = json.loads(json_match.group(1))
                return {"success": True, "plan": plan}
            
            return {"success": False, "error": "æ— æ³•è§£æé¡¹ç›®è§„åˆ’", "raw": reply}
            
        except Exception as e:
            print(f"[Agent] é¡¹ç›®è§„åˆ’å¤±è´¥: {e}")
            return {"success": False, "error": str(e)}
    
    async def generate_element_prompt(
        self,
        element_name: str,
        element_type: str,
        base_description: str,
        visual_style: str = "å‰åœåŠ›åŠ¨ç”»é£æ ¼"
    ) -> Dict[str, Any]:
        """ç”Ÿæˆå…ƒç´ çš„å›¾åƒæç¤ºè¯"""
        if not self.client:
            return {"error": "æœªé…ç½® LLM API Key"}
        
        try:
            prompt = ELEMENT_PROMPT_TEMPLATE.format(
                element_name=element_name,
                element_type=element_type,
                base_description=base_description,
                visual_style=visual_style
            )
            
            response = await self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„ AI å›¾åƒæç¤ºè¯å·¥ç¨‹å¸ˆã€‚"},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.7,
                max_tokens=1000
            )
            
            reply = response.choices[0].message.content or ""
            
            # æå– JSON
            json_match = re.search(r'```json\s*([\s\S]*?)\s*```', reply)
            if json_match:
                result = json.loads(json_match.group(1))
                return {"success": True, **result}
            
            return {"success": False, "error": "æ— æ³•è§£ææç¤ºè¯", "raw": reply}
            
        except Exception as e:
            return {"success": False, "error": str(e)}
    
    async def generate_shot_prompt(
        self,
        shot_name: str,
        shot_type: str,
        shot_description: str,
        elements: List[str],
        visual_style: str,
        narration: str
    ) -> Dict[str, Any]:
        """ç”Ÿæˆé•œå¤´çš„è§†é¢‘æç¤ºè¯"""
        if not self.client:
            return {"error": "æœªé…ç½® LLM API Key"}
        
        try:
            shot_type_info = SHOT_TYPES.get(shot_type, SHOT_TYPES["standard"])
            
            prompt = SHOT_PROMPT_TEMPLATE.format(
                shot_name=shot_name,
                shot_type=f"{shot_type_info['name']} ({shot_type_info['duration']})",
                shot_description=shot_description,
                elements=", ".join(elements),
                visual_style=visual_style,
                narration=narration
            )
            
            response = await self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„ AI è§†é¢‘æç¤ºè¯å·¥ç¨‹å¸ˆã€‚"},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.7,
                max_tokens=1000
            )
            
            reply = response.choices[0].message.content or ""
            
            # æå– JSON
            json_match = re.search(r'```json\s*([\s\S]*?)\s*```', reply)
            if json_match:
                result = json.loads(json_match.group(1))
                return {"success": True, **result}
            
            return {"success": False, "error": "æ— æ³•è§£ææç¤ºè¯", "raw": reply}
            
        except Exception as e:
            return {"success": False, "error": str(e)}
    
    def _parse_response(self, reply: str) -> Dict[str, Any]:
        """è§£æ LLM å“åº”"""
        # å°è¯•æå– JSON
        json_match = re.search(r'```json\s*([\s\S]*?)\s*```', reply)
        if json_match:
            try:
                data = json.loads(json_match.group(1))
                return {"type": "structured", "data": data, "content": reply}
            except json.JSONDecodeError:
                pass
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«ç‰¹å®šæŒ‡ä»¤
        if "ç”Ÿæˆè§’è‰²" in reply or "ç”Ÿæˆå…ƒç´ " in reply:
            return {"type": "action", "action": "generate_elements", "content": reply}
        
        if "ç”Ÿæˆåˆ†é•œ" in reply or "ç”Ÿæˆé•œå¤´" in reply:
            return {"type": "action", "action": "generate_shots", "content": reply}
        
        # æ™®é€šæ–‡æœ¬å“åº”
        return {"type": "text", "content": reply}
    
    def build_shot_prompt(
        self,
        shot_type: str,
        description: str,
        elements: List[str],
        narration: str,
        style: str = "cinematic"
    ) -> str:
        """æ„å»ºå®Œæ•´çš„é•œå¤´æç¤ºè¯"""
        shot_info = SHOT_TYPES.get(shot_type, SHOT_TYPES["standard"])
        
        # æ›¿æ¢å…ƒç´ å¼•ç”¨
        prompt_parts = [
            f"{shot_info['name']} ({shot_info['duration']})",
            description
        ]
        
        # æ·»åŠ æ—ç™½å¯¹é½
        if narration:
            prompt_parts.append(f"å¯¹é½æ—ç™½ï¼š'{narration}'")
        
        return " ".join(prompt_parts)
    
    def resolve_element_references(
        self,
        prompt: str,
        elements: Dict[str, Dict]
    ) -> str:
        """è§£ææç¤ºè¯ä¸­çš„å…ƒç´ å¼•ç”¨ï¼Œæ›¿æ¢ä¸ºå®é™…æè¿°"""
        def replace_element(match):
            element_id = match.group(1)
            if element_id in elements:
                return elements[element_id].get("description", element_id)
            return match.group(0)
        
        return re.sub(r'\[Element_(\w+)\]', replace_element, prompt)


class AgentProject:
    """Agent é¡¹ç›®æ•°æ®ç»“æ„"""
    
    def __init__(self, project_id: Optional[str] = None):
        self.id = project_id or f"agent_{uuid.uuid4().hex[:8]}"
        self.name = "æœªå‘½åé¡¹ç›®"
        self.creative_brief: Dict = {}
        self.elements: Dict[str, Dict] = {}
        self.segments: List[Dict] = []
        self.visual_assets: List[Dict] = []
        self.audio_assets: List[Dict] = []
        self.timeline: List[Dict] = []
        self.created_at = datetime.now().isoformat()
        self.updated_at = datetime.now().isoformat()
    
    def add_element(
        self,
        element_id: str,
        name: str,
        element_type: str,
        description: str,
        image_url: Optional[str] = None
    ) -> Dict:
        """æ·»åŠ å…ƒç´ """
        element = {
            "id": element_id,
            "name": name,
            "type": element_type,
            "description": description,
            "image_url": image_url,
            "created_at": datetime.now().isoformat()
        }
        self.elements[element_id] = element
        self.updated_at = datetime.now().isoformat()
        return element
    
    def add_segment(
        self,
        segment_id: str,
        name: str,
        description: str
    ) -> Dict:
        """æ·»åŠ æ®µè½"""
        segment = {
            "id": segment_id,
            "name": name,
            "description": description,
            "shots": [],
            "created_at": datetime.now().isoformat()
        }
        self.segments.append(segment)
        self.updated_at = datetime.now().isoformat()
        return segment
    
    def add_shot(
        self,
        segment_id: str,
        shot_id: str,
        name: str,
        shot_type: str,
        description: str,
        prompt: str,
        narration: str,
        duration: float = 5.0
    ) -> Optional[Dict]:
        """æ·»åŠ é•œå¤´åˆ°æ®µè½"""
        for segment in self.segments:
            if segment["id"] == segment_id:
                shot = {
                    "id": shot_id,
                    "name": name,
                    "type": shot_type,
                    "description": description,
                    "prompt": prompt,
                    "narration": narration,
                    "duration": duration,
                    "start_image_url": None,
                    "video_url": None,
                    "status": "pending",
                    "created_at": datetime.now().isoformat()
                }
                segment["shots"].append(shot)
                self.updated_at = datetime.now().isoformat()
                return shot
        return None
    
    def to_dict(self) -> Dict:
        """è½¬æ¢ä¸ºå­—å…¸"""
        return {
            "id": self.id,
            "name": self.name,
            "creative_brief": self.creative_brief,
            "elements": self.elements,
            "segments": self.segments,
            "visual_assets": self.visual_assets,
            "audio_assets": self.audio_assets,
            "timeline": self.timeline,
            "created_at": self.created_at,
            "updated_at": self.updated_at
        }
    
    @classmethod
    def from_dict(cls, data: Dict) -> "AgentProject":
        """ä»å­—å…¸åˆ›å»º"""
        project = cls(data.get("id"))
        project.name = data.get("name", "æœªå‘½åé¡¹ç›®")
        project.creative_brief = data.get("creative_brief", {})
        project.elements = data.get("elements", {})
        project.segments = data.get("segments", [])
        project.visual_assets = data.get("visual_assets", [])
        project.audio_assets = data.get("audio_assets", [])
        project.timeline = data.get("timeline", [])
        project.created_at = data.get("created_at", datetime.now().isoformat())
        project.updated_at = data.get("updated_at", datetime.now().isoformat())
        return project


class AgentExecutor:
    """Agent æ‰§è¡Œå™¨ - è´Ÿè´£æ‰¹é‡ç”Ÿæˆæµç¨‹
    
    å‚ç…§ Flova çš„æ¸è¿›å¼ç¡®è®¤æœºåˆ¶ï¼š
    1. æ¯ä¸ªé˜¶æ®µå®Œæˆåæš‚åœç­‰å¾…ç”¨æˆ·ç¡®è®¤
    2. æ”¯æŒä¸­æ–­å’Œæ¢å¤
    3. å®æ—¶è¿›åº¦å›è°ƒ
    """
    
    def __init__(
        self,
        agent_service: AgentService,
        image_service,  # ImageService
        video_service,  # VideoService
        storage: StorageService
    ):
        self.agent = agent_service
        self.image_service = image_service
        self.video_service = video_service
        self.storage = storage
        self._cancelled = False
    
    def cancel(self):
        """å–æ¶ˆæ‰§è¡Œ"""
        self._cancelled = True
    
    async def generate_all_elements(
        self,
        project: AgentProject,
        visual_style: str = "å‰åœåŠ›åŠ¨ç”»é£æ ¼",
        on_progress: Optional[Callable[[str, int, int, Dict], None]] = None
    ) -> Dict[str, Any]:
        """æ‰¹é‡ç”Ÿæˆæ‰€æœ‰å…ƒç´ å›¾ç‰‡
        
        Args:
            project: é¡¹ç›®å¯¹è±¡
            visual_style: è§†è§‰é£æ ¼
            on_progress: è¿›åº¦å›è°ƒ (element_id, current, total, result)
        
        Returns:
            {success: bool, generated: int, failed: int, results: [...]}
        """
        self._cancelled = False
        elements = list(project.elements.values())
        total = len(elements)
        generated = 0
        failed = 0
        results = []
        
        for i, element in enumerate(elements):
            if self._cancelled:
                break
            
            # è·³è¿‡å·²æœ‰å›¾ç‰‡çš„å…ƒç´ 
            if element.get("image_url"):
                results.append({
                    "element_id": element["id"],
                    "status": "skipped",
                    "message": "å·²æœ‰å›¾ç‰‡"
                })
                continue
            
            try:
                # ç”Ÿæˆä¼˜åŒ–çš„æç¤ºè¯
                prompt_result = await self.agent.generate_element_prompt(
                    element["name"],
                    element["type"],
                    element["description"],
                    visual_style
                )
                
                if not prompt_result.get("success"):
                    # ä½¿ç”¨åŸå§‹æè¿°ä½œä¸ºæç¤ºè¯
                    prompt = f"{element['description']}, {visual_style}, high quality, detailed"
                    negative_prompt = "blurry, low quality, distorted"
                else:
                    prompt = prompt_result.get("prompt", element["description"])
                    negative_prompt = prompt_result.get("negative_prompt", "blurry, low quality")
                
                # ç”Ÿæˆå›¾ç‰‡
                image_result = await self.image_service.generate(
                    prompt=prompt,
                    negative_prompt=negative_prompt,
                    width=1024,
                    height=1024
                )
                
                image_url = image_result.get("url")
                
                # æ›´æ–°å…ƒç´ 
                project.elements[element["id"]]["image_url"] = image_url
                project.elements[element["id"]]["prompt"] = prompt
                
                # æ·»åŠ åˆ°è§†è§‰èµ„äº§
                project.visual_assets.append({
                    "id": f"asset_{element['id']}",
                    "url": image_url,
                    "type": "element",
                    "element_id": element["id"]
                })
                
                generated += 1
                result = {
                    "element_id": element["id"],
                    "status": "success",
                    "image_url": image_url
                }
                results.append(result)
                
                if on_progress:
                    on_progress(element["id"], i + 1, total, result)
                    
            except Exception as e:
                failed += 1
                result = {
                    "element_id": element["id"],
                    "status": "failed",
                    "error": str(e)
                }
                results.append(result)
                
                if on_progress:
                    on_progress(element["id"], i + 1, total, result)
        
        # ä¿å­˜é¡¹ç›®
        self.storage.save_agent_project(project.to_dict())
        
        return {
            "success": failed == 0,
            "generated": generated,
            "failed": failed,
            "total": total,
            "results": results
        }
    
    async def generate_all_start_frames(
        self,
        project: AgentProject,
        visual_style: str = "å‰åœåŠ›åŠ¨ç”»é£æ ¼",
        on_progress: Optional[Callable[[str, int, int, Dict], None]] = None
    ) -> Dict[str, Any]:
        """æ‰¹é‡ç”Ÿæˆæ‰€æœ‰é•œå¤´çš„èµ·å§‹å¸§
        
        Args:
            project: é¡¹ç›®å¯¹è±¡
            visual_style: è§†è§‰é£æ ¼
            on_progress: è¿›åº¦å›è°ƒ (shot_id, current, total, result)
        """
        self._cancelled = False
        
        # æ”¶é›†æ‰€æœ‰é•œå¤´
        all_shots = []
        for segment in project.segments:
            for shot in segment.get("shots", []):
                all_shots.append((segment["id"], shot))
        
        total = len(all_shots)
        generated = 0
        failed = 0
        results = []
        
        for i, (segment_id, shot) in enumerate(all_shots):
            if self._cancelled:
                break
            
            # è·³è¿‡å·²æœ‰èµ·å§‹å¸§çš„é•œå¤´
            if shot.get("start_image_url"):
                results.append({
                    "shot_id": shot["id"],
                    "status": "skipped",
                    "message": "å·²æœ‰èµ·å§‹å¸§"
                })
                continue
            
            try:
                # è§£æå…ƒç´ å¼•ç”¨ï¼Œæ„å»ºå®Œæ•´æç¤ºè¯
                prompt = shot.get("prompt", shot.get("description", ""))
                
                # æ›¿æ¢ [Element_XXX] å¼•ç”¨
                resolved_prompt = self._resolve_element_references(prompt, project.elements)
                
                # æ·»åŠ é£æ ¼å’Œè´¨é‡å…³é”®è¯
                full_prompt = f"{resolved_prompt}, {visual_style}, cinematic lighting, high quality, detailed"
                
                # ç”Ÿæˆå›¾ç‰‡
                image_result = await self.image_service.generate(
                    prompt=full_prompt,
                    negative_prompt="blurry, low quality, distorted, deformed",
                    width=1280,
                    height=720
                )
                
                image_url = image_result.get("url")
                
                # æ›´æ–°é•œå¤´
                shot["start_image_url"] = image_url
                shot["resolved_prompt"] = resolved_prompt
                shot["status"] = "frame_ready"
                
                # æ·»åŠ åˆ°è§†è§‰èµ„äº§
                project.visual_assets.append({
                    "id": f"frame_{shot['id']}",
                    "url": image_url,
                    "type": "start_frame",
                    "shot_id": shot["id"]
                })
                
                generated += 1
                result = {
                    "shot_id": shot["id"],
                    "status": "success",
                    "image_url": image_url
                }
                results.append(result)
                
                if on_progress:
                    on_progress(shot["id"], i + 1, total, result)
                    
            except Exception as e:
                failed += 1
                shot["status"] = "frame_failed"
                result = {
                    "shot_id": shot["id"],
                    "status": "failed",
                    "error": str(e)
                }
                results.append(result)
                
                if on_progress:
                    on_progress(shot["id"], i + 1, total, result)
        
        # ä¿å­˜é¡¹ç›®
        self.storage.save_agent_project(project.to_dict())
        
        return {
            "success": failed == 0,
            "generated": generated,
            "failed": failed,
            "total": total,
            "results": results
        }
    
    async def generate_all_videos(
        self,
        project: AgentProject,
        resolution: str = "720p",
        on_progress: Optional[Callable[[str, int, int, Dict], None]] = None,
        on_task_created: Optional[Callable[[str, str], None]] = None
    ) -> Dict[str, Any]:
        """æ‰¹é‡ç”Ÿæˆæ‰€æœ‰é•œå¤´çš„è§†é¢‘
        
        Args:
            project: é¡¹ç›®å¯¹è±¡
            resolution: åˆ†è¾¨ç‡
            on_progress: è¿›åº¦å›è°ƒ (shot_id, current, total, result)
            on_task_created: ä»»åŠ¡åˆ›å»ºå›è°ƒ (shot_id, task_id)
        """
        self._cancelled = False
        
        # æ”¶é›†æ‰€æœ‰æœ‰èµ·å§‹å¸§çš„é•œå¤´
        all_shots = []
        for segment in project.segments:
            for shot in segment.get("shots", []):
                if shot.get("start_image_url"):
                    all_shots.append((segment["id"], shot))
        
        total = len(all_shots)
        generated = 0
        failed = 0
        results = []
        pending_tasks = []  # å¾…è½®è¯¢çš„ä»»åŠ¡
        
        for i, (segment_id, shot) in enumerate(all_shots):
            if self._cancelled:
                break
            
            # è·³è¿‡å·²æœ‰è§†é¢‘çš„é•œå¤´
            if shot.get("video_url"):
                results.append({
                    "shot_id": shot["id"],
                    "status": "skipped",
                    "message": "å·²æœ‰è§†é¢‘"
                })
                continue
            
            try:
                # æ„å»ºè§†é¢‘æç¤ºè¯
                video_prompt = shot.get("resolved_prompt", shot.get("prompt", ""))
                
                # ç”Ÿæˆè§†é¢‘
                video_result = await self.video_service.generate(
                    image_url=shot["start_image_url"],
                    prompt=video_prompt,
                    duration=shot.get("duration", 5),
                    resolution=resolution
                )
                
                task_id = video_result.get("task_id")
                status = video_result.get("status")
                
                shot["video_task_id"] = task_id
                shot["status"] = "video_processing"
                
                if on_task_created:
                    on_task_created(shot["id"], task_id)
                
                # å¦‚æœæ˜¯å¼‚æ­¥ä»»åŠ¡ï¼ŒåŠ å…¥å¾…è½®è¯¢åˆ—è¡¨
                if status in ["processing", "pending", "submitted"]:
                    pending_tasks.append({
                        "shot_id": shot["id"],
                        "task_id": task_id,
                        "shot": shot
                    })
                elif status == "completed" or status == "succeeded":
                    shot["video_url"] = video_result.get("video_url")
                    shot["status"] = "video_ready"
                    generated += 1
                    
                    # æ·»åŠ åˆ°è§†è§‰èµ„äº§
                    project.visual_assets.append({
                        "id": f"video_{shot['id']}",
                        "url": shot["video_url"],
                        "type": "video",
                        "shot_id": shot["id"],
                        "duration": shot.get("duration")
                    })
                
                result = {
                    "shot_id": shot["id"],
                    "status": "submitted",
                    "task_id": task_id
                }
                results.append(result)
                
                if on_progress:
                    on_progress(shot["id"], i + 1, total, result)
                    
            except Exception as e:
                failed += 1
                shot["status"] = "video_failed"
                result = {
                    "shot_id": shot["id"],
                    "status": "failed",
                    "error": str(e)
                }
                results.append(result)
                
                if on_progress:
                    on_progress(shot["id"], i + 1, total, result)
        
        # è½®è¯¢ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
        if pending_tasks and not self._cancelled:
            await self._poll_video_tasks(project, pending_tasks, on_progress)
            generated = sum(1 for t in pending_tasks if t["shot"].get("video_url"))
            failed += sum(1 for t in pending_tasks if t["shot"].get("status") == "video_failed")
        
        # ä¿å­˜é¡¹ç›®
        self.storage.save_agent_project(project.to_dict())
        
        return {
            "success": failed == 0,
            "generated": generated,
            "failed": failed,
            "total": total,
            "results": results
        }
    
    async def _poll_video_tasks(
        self,
        project: AgentProject,
        pending_tasks: List[Dict],
        on_progress: Optional[Callable] = None,
        max_wait: int = 600,  # æœ€é•¿ç­‰å¾…10åˆ†é’Ÿ
        poll_interval: int = 5
    ):
        """è½®è¯¢è§†é¢‘ä»»åŠ¡çŠ¶æ€"""
        start_time = asyncio.get_event_loop().time()
        
        while pending_tasks and not self._cancelled:
            elapsed = asyncio.get_event_loop().time() - start_time
            if elapsed > max_wait:
                print(f"[AgentExecutor] è§†é¢‘ç”Ÿæˆè¶…æ—¶ï¼Œ{len(pending_tasks)} ä¸ªä»»åŠ¡æœªå®Œæˆ")
                break
            
            for task_info in pending_tasks[:]:  # å¤åˆ¶åˆ—è¡¨ä»¥ä¾¿ä¿®æ”¹
                try:
                    result = await self.video_service.check_task_status(task_info["task_id"])
                    status = result.get("status")
                    
                    if status in ["completed", "succeeded"]:
                        shot = task_info["shot"]
                        shot["video_url"] = result.get("video_url")
                        shot["status"] = "video_ready"
                        
                        # æ·»åŠ åˆ°è§†è§‰èµ„äº§
                        project.visual_assets.append({
                            "id": f"video_{shot['id']}",
                            "url": shot["video_url"],
                            "type": "video",
                            "shot_id": shot["id"],
                            "duration": shot.get("duration")
                        })
                        
                        pending_tasks.remove(task_info)
                        
                        if on_progress:
                            on_progress(shot["id"], -1, -1, {
                                "status": "completed",
                                "video_url": shot["video_url"]
                            })
                    
                    elif status == "failed":
                        shot = task_info["shot"]
                        shot["status"] = "video_failed"
                        shot["error"] = result.get("error", "è§†é¢‘ç”Ÿæˆå¤±è´¥")
                        pending_tasks.remove(task_info)
                        
                        if on_progress:
                            on_progress(shot["id"], -1, -1, {
                                "status": "failed",
                                "error": shot["error"]
                            })
                            
                except Exception as e:
                    print(f"[AgentExecutor] è½®è¯¢ä»»åŠ¡ {task_info['task_id']} å¤±è´¥: {e}")
            
            if pending_tasks:
                await asyncio.sleep(poll_interval)
    
    def _resolve_element_references(self, prompt: str, elements: Dict[str, Dict]) -> str:
        """è§£ææç¤ºè¯ä¸­çš„å…ƒç´ å¼•ç”¨"""
        def replace_element(match):
            element_id = match.group(0)  # å®Œæ•´åŒ¹é… [Element_XXX]
            element_key = match.group(1)  # XXX éƒ¨åˆ†
            
            # å°è¯•å¤šç§åŒ¹é…æ–¹å¼
            full_id = f"Element_{element_key}"
            element = elements.get(full_id) or elements.get(element_id) or elements.get(element_key)
            
            if element:
                # å¦‚æœå…ƒç´ æœ‰å›¾ç‰‡ï¼Œä½¿ç”¨ç®€çŸ­æè¿°ï¼›å¦åˆ™ä½¿ç”¨å®Œæ•´æè¿°
                if element.get("image_url"):
                    return element.get("name", element_key)
                return element.get("description", element_key)
            return match.group(0)
        
        return re.sub(r'\[Element_(\w+)\]', replace_element, prompt)
    
    async def execute_full_pipeline(
        self,
        project: AgentProject,
        visual_style: str = "å‰åœåŠ›åŠ¨ç”»é£æ ¼",
        resolution: str = "720p",
        on_stage_complete: Optional[Callable[[str, Dict], None]] = None,
        on_progress: Optional[Callable[[str, str, int, int, Dict], None]] = None
    ) -> Dict[str, Any]:
        """æ‰§è¡Œå®Œæ•´çš„ç”Ÿæˆæµç¨‹
        
        Flova é£æ ¼çš„æ¸è¿›å¼æ‰§è¡Œï¼š
        1. ç”Ÿæˆæ‰€æœ‰å…ƒç´ å›¾ç‰‡
        2. ç”Ÿæˆæ‰€æœ‰èµ·å§‹å¸§
        3. ç”Ÿæˆæ‰€æœ‰è§†é¢‘
        
        Args:
            project: é¡¹ç›®å¯¹è±¡
            visual_style: è§†è§‰é£æ ¼
            resolution: è§†é¢‘åˆ†è¾¨ç‡
            on_stage_complete: é˜¶æ®µå®Œæˆå›è°ƒ (stage_name, result)
            on_progress: è¿›åº¦å›è°ƒ (stage, item_id, current, total, result)
        """
        self._cancelled = False
        pipeline_result = {
            "stages": {},
            "success": True,
            "total_generated": 0,
            "total_failed": 0
        }
        
        # é˜¶æ®µ1: ç”Ÿæˆå…ƒç´ å›¾ç‰‡
        print("[AgentExecutor] é˜¶æ®µ1: ç”Ÿæˆå…ƒç´ å›¾ç‰‡")
        elements_result = await self.generate_all_elements(
            project,
            visual_style,
            on_progress=lambda eid, cur, tot, res: on_progress("elements", eid, cur, tot, res) if on_progress else None
        )
        pipeline_result["stages"]["elements"] = elements_result
        pipeline_result["total_generated"] += elements_result["generated"]
        pipeline_result["total_failed"] += elements_result["failed"]
        
        if on_stage_complete:
            on_stage_complete("elements", elements_result)
        
        if self._cancelled:
            pipeline_result["success"] = False
            pipeline_result["cancelled_at"] = "elements"
            return pipeline_result
        
        # é˜¶æ®µ2: ç”Ÿæˆèµ·å§‹å¸§
        print("[AgentExecutor] é˜¶æ®µ2: ç”Ÿæˆèµ·å§‹å¸§")
        frames_result = await self.generate_all_start_frames(
            project,
            visual_style,
            on_progress=lambda sid, cur, tot, res: on_progress("frames", sid, cur, tot, res) if on_progress else None
        )
        pipeline_result["stages"]["frames"] = frames_result
        pipeline_result["total_generated"] += frames_result["generated"]
        pipeline_result["total_failed"] += frames_result["failed"]
        
        if on_stage_complete:
            on_stage_complete("frames", frames_result)
        
        if self._cancelled:
            pipeline_result["success"] = False
            pipeline_result["cancelled_at"] = "frames"
            return pipeline_result
        
        # é˜¶æ®µ3: ç”Ÿæˆè§†é¢‘
        print("[AgentExecutor] é˜¶æ®µ3: ç”Ÿæˆè§†é¢‘")
        videos_result = await self.generate_all_videos(
            project,
            resolution,
            on_progress=lambda sid, cur, tot, res: on_progress("videos", sid, cur, tot, res) if on_progress else None
        )
        pipeline_result["stages"]["videos"] = videos_result
        pipeline_result["total_generated"] += videos_result["generated"]
        pipeline_result["total_failed"] += videos_result["failed"]
        
        if on_stage_complete:
            on_stage_complete("videos", videos_result)
        
        pipeline_result["success"] = pipeline_result["total_failed"] == 0
        
        return pipeline_result
